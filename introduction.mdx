---
title: Cerebras API Developer Platform
---

The Cerebras API offers developers a low-latency solution for AI model inference powered by Cerebras Wafer-Scale Engines and CS-3 systems. We invite developers to explore the new possibilities that our high-speed inferencing solution unlocks.

Currently, the Cerebras API provides access to two models: Metaâ€™s Llama 3 8B and 70B models. Both models are instruction-tuned and can be used for conversational applications. 


<CardGroup cols={2}>
  <Card
    title="Llama-3-8B"
  >
    * Parameters: 8 billion
    * Knowledge cutoff: March 2023
    * Context Length: 8192
    * Training Tokens: 15 trillion
    
  </Card>
  <Card
    title="Llama-3-70B"
  >
    * Parameters: 70 billion
    * Knowledge cutoff: December 2023
    * Context Length: 8192
    * Training Tokens: 15 trillion  
    </Card>
</CardGroup>

<Card title="QuickStart Guide" href="/quickstart">
Get started by building your first application using our QuickStart guide
<br></br>

<Frame>
  <img src="/images/quickstart-image.png" />
</Frame>

</Card>

## Resources
* Play with our [live chatbot demo](https://zlgwsxmqyp6tncmuzr7pimpvru0ksaxz.lambda-url.us-west-1.on.aws/chat).
* Experiment with our inference solution in the [playground](https://zlgwsxmqyp6tncmuzr7pimpvru0ksaxz.lambda-url.us-west-1.on.aws/platform) before making an API call.
* Explore our API reference documentation. 
