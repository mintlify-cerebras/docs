---
title: Cerebras API
---

The Cerebras API offers developers a low-latency solution for AI model inference powered by Cerebras Wafer-Scale Engines and CS-3 systems. We invite developers to explore the new possibilities that our high-speed inferencing solution unlocks.

Currently, the Cerebras API provides access to two models: Metaâ€™s Llama 3.1 8B and 70B models. Both models are instruction-tuned and can be used for conversational applications. 


<CardGroup cols={2}>
  <Card
    title="Llama-3.1-8B"
  >
    * Parameters: 8 billion
    * Knowledge cutoff: March 2023
    * Context Length: 8192
    * Training Tokens: 15 trillion
    
  </Card>
  <Card
    title="Llama-3.1-70B"
  >
    * Parameters: 70 billion
    * Knowledge cutoff: December 2023
    * Context Length: 8192
    * Training Tokens: 15 trillion  
    </Card>
</CardGroup>

<Card title="QuickStart Guide" href="/quickstart">
Get started by building your first application using our QuickStart guide
<br></br>

<Frame>
  <img src="/images/quickstart-image.png" />
</Frame>

</Card>

## Resources
* Play with our [live chatbot demo](https://d1qvsf2j2et3q6.cloudfront.net/).
* Experiment with our inference solution in the [playground](https://d3r97n7qwktix5.cloudfront.net/) before making an API call.
* Explore our [API reference](https://inference-docs.cerebras.ai/api-reference/chat-completions) documentation. 
