---
title: 'Quickstart'
---

This QuickStart guide is designed to assist you in making your first API call. If you are an experienced AI applications developer, you may find it more beneficial to go directly to the [API reference documentation](https://inference-docs.cerebras.ai/api-reference/chat-completions).

If you would like to interact with the models using Cerebras’ Inference solution before making an API call, please visit the [developer playground](https://d3r97n7qwktix5.cloudfront.net/).

This guide will walk you through:
* Setting up your developer environment
* Installing the Cerebras Inference library
* Making your first request to the Cerebras API

## Prerequisites

To complete this guide, you will need:
* A Cerebras account
* A Cerebras Inference API key
* Python 3.7+ or TypeScript 4.5+

## Step 1: Set up your API key

The first thing you will need is a valid API key. Please visit [this link](https://d3r97n7qwktix5.cloudfront.net/) and navigate to “API Keys” on the left nav bar.

For security reasons and to avoid configuring your API key each time, it is recommended to set your API key as an environment variable. You can do this by running the following command in your terminal:

```bash
export CEREBRAS_API_KEY="your-api-key-here"
```

## Step 2: Install the Cerebras Inference library

The Cerebras Inference library is available for download and installation through the Python Package Index (PyPI) and the npm package manager. To install the library run either of the following commands in your terminal, based on your language of choice:

<CodeGroup>
```bash Python
pip3 install https://cerebras-cloud-sdk.s3.us-west-1.amazonaws.com/test/cerebras_cloud_sdk-0.5.0-py3-none-any.whl
```

```bash Node.js
npm install https://cerebras-cloud-sdk.s3.us-west-1.amazonaws.com/test/cerebras_cloud_sdk-0.5.0.tgz
```
</CodeGroup>

<Note>Note: You can also call the underlying API directly (see cURL request example below in Step 3).</Note>

## Step 3: Making an API request

Once you have configured your API key, you are ready to send your first API request.

The following code snippets demonstrate how to make an API request to the Cerebras API to perform a chat completion.

<CodeGroup>
```python Python
import os
from cerebras.cloud.sdk import Cerebras
client = Cerebras(
    # This is the default and can be omitted
    api_key=os.environ.get("CEREBRAS_API_KEY"),
)
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "Why is fast inference important?",
        }
],
    model="llama3.1-8b",
)
print(chat_completion)
```

```javascript Node.js

import Cerebras from 'cerebras_cloud_sdk';

const client = new Cerebras({
  apiKey: process.env['CEREBRAS_API_KEY'], // This is the default and can be omitted
});

async function main() {
  const completionCreateResponse = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Why is fast inference important?' }],
    model: 'llama3.1-8b',
  });

  console.log(completionCreateResponse);
}

main();
```

```cli cURL
curl --location 'https://d1n704mb908frr.cloudfront.net/v1/chat/completions' \
--header 'Content-Type: application/json' \
--header "Authorization: Bearer ${CEREBRAS_API_KEY}" \
--data '{
  "model": "llama3.1-8b",
  "stream": false,
  "messages": [{"content": "why is fast inference important?", "role": "user"}],
  "prompt": "",
  "temperature": 0,
  "stop_sequence": "",
  "max_tokens": -1,
  "seed": 0,
  "top_p": 1
}'
```
</CodeGroup>

## Next Steps
* Check out our [API Reference]('https://inference-docs.cerebras.ai/api-reference/chat-completions') to learn about the details of our available endpoints and request parameters.
* Learn how to [stream responses]('https://inference-docs.cerebras.ai/streaming')